{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Évaluation qualitative\n",
    "> Comparons les différents algorithmes en terme de qualité de prédiction et de temps de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Comparaison entre algorithmes\n",
    "\n",
    "Charger les bibliothèques et les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(0)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data import *\n",
    "import popularity\n",
    "import knn\n",
    "import knn_item_based\n",
    "import svd\n",
    "import als\n",
    "from svd import *\n",
    "from eval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 40), 389)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = load_data(tiny=True)\n",
    "M.shape, np.sum(~np.isnan(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Liste d'algorithmes à comparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# recommenders = [\n",
    "#     {\"fn\": popularity.complete, \"label\": \"popularity\"},\n",
    "#     {\"fn\": lambda M_train: knn.complete(M_train, k=10), \"label\": \"knn10\"},\n",
    "#     {\"fn\": lambda M_train: svd.complete(M_train, k=10), \"label\": \"svd0_10\"},\n",
    "#     {\"fn\": lambda M_train: svd.complete(M_train, k=20), \"label\": \"svd0_20\"},\n",
    "#     {\"fn\": lambda M_train: svd.complete(M_train, k=10, replaceNA_fn=replaceNA_with_mean), \"label\": \"svdMean_10\"},\n",
    "#     {\"fn\": lambda M_train: svd.complete(M_train, k=20, replaceNA_fn=replaceNA_with_mean), \"label\": \"svdMean_20\"},\n",
    "#     {\"fn\": lambda M_train: als.complete(M_train, k=10, lambd=10**-1, n_iter=5), \"label\": \"als10\"},\n",
    "#     {\"fn\": lambda M_train: als.complete(M_train, k=40, lambd=10**-1, n_iter=5), \"label\": \"als40\"},\n",
    "#     {\"fn\": lambda M_train: complete_softImpute(M_train, lambd=10**+1, n_iter=20), \"label\": \"softImpute10\"},\n",
    "#     {\"fn\": lambda M_train: complete_softImpute(M_train, lambd=10**0, n_iter=20), \"label\": \"softImpute1\"},\n",
    "#     {\"fn\": lambda M_train: complete_softImpute(M_train, lambd=10**-1, n_iter=20), \"label\": \"softImpute0_1\"},\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche de meilleiur valeur de K du KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester plusieurs valeurs de k pour KNN\n",
    "k_values = list(range(2, 30))\n",
    "recommenders = [\n",
    "    {\"fn\": lambda M_train, k=k: knn.complete(M_train, k=k), \"label\": f\"knn{k}\"} \n",
    "    for k in k_values\n",
    "]\n",
    "\n",
    "# Comparaison des performances\n",
    "res_knn_k = quantitative_comparison(RMSE, M, recommenders, prop=0.8, nrep=4)\n",
    "\n",
    "# Trouver les meilleures valeur de k\n",
    "best_k = res_knn_k.nsmallest(5, 'validation score')\n",
    "\n",
    "\n",
    "# Sauvegarde des résultats\n",
    "best_k.to_csv(\"best_knn_result.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommender</th>\n",
       "      <th>validation score</th>\n",
       "      <th>training score</th>\n",
       "      <th>computation time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>knn16</td>\n",
       "      <td>1.075089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>knn13</td>\n",
       "      <td>1.075189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.654125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>knn17</td>\n",
       "      <td>1.075297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.824311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>knn15</td>\n",
       "      <td>1.075620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knn12</td>\n",
       "      <td>1.076069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommender  validation score  training score  computation time\n",
       "14       knn16          1.075089             0.0          0.640961\n",
       "11       knn13          1.075189             0.0          0.654125\n",
       "15       knn17          1.075297             0.0          0.824311\n",
       "13       knn15          1.075620             0.0          0.786097\n",
       "10       knn12          1.076069             0.0          0.855000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage des résultats\n",
    "best_k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche de meilleiur valeur de K du KNN Item Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recommenders = [\n",
    "    {\"fn\": lambda M_train, k=k: knn_item_based.complete_item_based(M_train, k=k), \"label\": f\"knn_item{k}\"} \n",
    "    for k in k_values\n",
    "]\n",
    "\n",
    "# Comparaison des performances\n",
    "res_knn_item_k = quantitative_comparison(RMSE, M, recommenders, prop=0.8, nrep=4)\n",
    "\n",
    "# Trouver les meilleures valeur de k\n",
    "best_k_knn_item = res_knn_item_k.nsmallest(5, 'validation score')\n",
    "\n",
    "\n",
    "# Sauvegarde des résultats\n",
    "best_k_knn_item.to_csv(\"best_knn_item_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommender</th>\n",
       "      <th>validation score</th>\n",
       "      <th>training score</th>\n",
       "      <th>computation time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>knn_item29</td>\n",
       "      <td>1.044027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>knn_item28</td>\n",
       "      <td>1.044084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>knn_item27</td>\n",
       "      <td>1.044196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>knn_item25</td>\n",
       "      <td>1.044271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>knn_item26</td>\n",
       "      <td>1.044482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.622691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommender  validation score  training score  computation time\n",
       "27  knn_item29          1.044027             0.0          0.820268\n",
       "26  knn_item28          1.044084             0.0          0.721500\n",
       "25  knn_item27          1.044196             0.0          0.447948\n",
       "23  knn_item25          1.044271             0.0          0.450590\n",
       "24  knn_item26          1.044482             0.0          0.622691"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k_knn_item.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche de meilleiur valeur de K du SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester plusieurs valeurs de k pour KNN\n",
    "recommenders = [\n",
    "    {\"fn\": lambda M_train, k=k: svd.complete(M_train, k=k), \"label\": f\"svd{k}\"} \n",
    "    for k in k_values\n",
    "]\n",
    "\n",
    "# Comparaison des performances\n",
    "res_svd_k = quantitative_comparison(RMSE, M, recommenders, prop=0.8, nrep=4)\n",
    "\n",
    "# Trouver les meilleures valeur de k\n",
    "best_k_svd = res_svd_k.nsmallest(5, 'validation score')\n",
    "\n",
    "\n",
    "# Sauvegarde des résultats\n",
    "best_k_svd.to_csv(\"best_svd_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommender</th>\n",
       "      <th>validation score</th>\n",
       "      <th>training score</th>\n",
       "      <th>computation time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd2</td>\n",
       "      <td>3.073598</td>\n",
       "      <td>2.408178</td>\n",
       "      <td>0.005718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svd3</td>\n",
       "      <td>3.264302</td>\n",
       "      <td>2.224919</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svd4</td>\n",
       "      <td>3.353896</td>\n",
       "      <td>2.039790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svd5</td>\n",
       "      <td>3.420154</td>\n",
       "      <td>1.862982</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svd6</td>\n",
       "      <td>3.489354</td>\n",
       "      <td>1.702019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recommender  validation score  training score  computation time\n",
       "0        svd2          3.073598        2.408178          0.005718\n",
       "1        svd3          3.264302        2.224919          0.000000\n",
       "2        svd4          3.353896        2.039790          0.000000\n",
       "3        svd5          3.420154        1.862982          0.000000\n",
       "4        svd6          3.489354        1.702019          0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k_svd.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation par la moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SobjioLagnol(Externa\\OneDrive - Majorel\\Bureau\\SystRecomandation\\svd.py:21: RuntimeWarning: Mean of empty slice\n",
      "  col_mean = np.nanmean(M_train, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Tester plusieurs valeurs de k pour KNN\n",
    "recommenders = [\n",
    "    {\"fn\": lambda M_train, k=k: svd.complete(M_train, k=k,replaceNA_fn=replaceNA_with_mean), \"label\": f\"svd{k}\"} \n",
    "    for k in k_values\n",
    "]\n",
    "\n",
    "# Comparaison des performances\n",
    "res_svd_k = quantitative_comparison(RMSE, M, recommenders, prop=0.8, nrep=4)\n",
    "\n",
    "# Trouver les meilleures valeur de k\n",
    "best_k_svd = res_svd_k.nsmallest(5, 'validation score')\n",
    "\n",
    "\n",
    "# Sauvegarde des résultats\n",
    "best_k_svd.to_csv(\"best_svd_Imput_moy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommender</th>\n",
       "      <th>validation score</th>\n",
       "      <th>training score</th>\n",
       "      <th>computation time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd2</td>\n",
       "      <td>1.181793</td>\n",
       "      <td>0.309941</td>\n",
       "      <td>0.003669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>svd24</td>\n",
       "      <td>1.182905</td>\n",
       "      <td>0.032138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svd13</td>\n",
       "      <td>1.182997</td>\n",
       "      <td>0.115966</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>svd26</td>\n",
       "      <td>1.183266</td>\n",
       "      <td>0.022661</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svd14</td>\n",
       "      <td>1.183382</td>\n",
       "      <td>0.105476</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommender  validation score  training score  computation time\n",
       "0         svd2          1.181793        0.309941          0.003669\n",
       "22       svd24          1.182905        0.032138          0.000000\n",
       "11       svd13          1.182997        0.115966          0.000000\n",
       "24       svd26          1.183266        0.022661          0.000000\n",
       "12       svd14          1.183382        0.105476          0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k_svd.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l'imputation pas la moyenne est meilleur "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche de meilleiur valeur de K pour ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester plusieurs valeurs de k pour KNN\n",
    "recommenders = [\n",
    "    {\"fn\": lambda M_train, k=k: als.complete(M_train, k=k), \"label\": f\"svd{k}\"} \n",
    "    for k in k_values\n",
    "]\n",
    "\n",
    "# Comparaison des performances\n",
    "res_als_k = quantitative_comparison(RMSE, M, recommenders, prop=0.8, nrep=4)\n",
    "\n",
    "# Trouver les meilleures valeur de k\n",
    "best_k_als = res_als_k.nsmallest(5, 'validation score')\n",
    "\n",
    "\n",
    "# Sauvegarde des résultats\n",
    "best_k_als.to_csv(\"best_als_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommender</th>\n",
       "      <th>validation score</th>\n",
       "      <th>training score</th>\n",
       "      <th>computation time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>svd21</td>\n",
       "      <td>1.289165</td>\n",
       "      <td>0.028175</td>\n",
       "      <td>0.170036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>svd29</td>\n",
       "      <td>1.322864</td>\n",
       "      <td>0.035901</td>\n",
       "      <td>0.260192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>svd17</td>\n",
       "      <td>1.338270</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>0.021820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>svd15</td>\n",
       "      <td>1.341688</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.031311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>svd23</td>\n",
       "      <td>1.344799</td>\n",
       "      <td>0.031009</td>\n",
       "      <td>0.136568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommender  validation score  training score  computation time\n",
       "19       svd21          1.289165        0.028175          0.170036\n",
       "27       svd29          1.322864        0.035901          0.260192\n",
       "15       svd17          1.338270        0.026912          0.021820\n",
       "13       svd15          1.341688        0.024003          0.031311\n",
       "21       svd23          1.344799        0.031009          0.136568"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k_als.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4  Autres Metriques d'evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Description des métriques et protocole d'évaluation**  \n",
    "\n",
    "- **MAE (Mean Absolute Error)** :  \n",
    "  - Objectif : Mesure l'erreur absolue moyenne entre les prédictions et les valeurs réelles.  \n",
    "  - Protocole d'évaluation :  \n",
    "    1. Séparer les données en ensemble d'entraînement et de validation.  \n",
    "    2. Appliquer l’algorithme de recommandation pour compléter la matrice d’évaluation.  \n",
    "    3. Comparer les prédictions aux valeurs réelles en calculant la moyenne des erreurs absolues.  \n",
    "    4. Une faible valeur de MAE indique de meilleures performances.  \n",
    "\n",
    "- **Precision k** :  \n",
    "  - Objectif : Mesure la proportion d'items recommandés dans le top-k qui sont effectivement pertinents.  \n",
    "  - Protocole d’évaluation :  \n",
    "    1. Définir un ensemble de validation avec des interactions utilisateur-item connues.  \n",
    "    2. Générer une liste de recommandations pour chaque utilisateur.  \n",
    "    3. Comparer les k premiers items recommandés avec la liste des items pertinents.  \n",
    "    4. Calculer la proportion d’items corrects dans le top-k recommandé.  \n",
    "    5. La précision est élevée si la majorité des recommandations sont pertinentes.  \n",
    "\n",
    "- **Recall k** :  \n",
    "  - Objectif : Évalue la capacité du système à recommander tous les items pertinents.  \n",
    "  - Protocole d’évaluation :  \n",
    "    1. Identifier la liste des items pertinents pour un utilisateur.  \n",
    "    2. Vérifier combien d’items pertinents apparaissent dans le top-k recommandé.  \n",
    "    3. Calculer la proportion d’items pertinents retrouvés sur l’ensemble des items pertinents existants.  \n",
    "    4. Un rappel élevé indique que le modèle capte bien les préférences des utilisateurs.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Dépendance des valeurs de précision et de rappel au nombre d'items recommandés (k)**  \n",
    "- Le choix de **k** influence directement ces métriques :  \n",
    "  - Si **k est trop petit**, la précision peut être élevée, mais le rappel sera faible.  \n",
    "  - Si **k est trop grand**, le rappel peut être élevé, mais la précision risque de baisser.  \n",
    "- L’évaluation doit être faite avec différents k pour comparer l'impact sur la performance des modèles.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Influence du choix du \"candidate set\"**  \n",
    "- Le **candidate set** représente l’ensemble des items parmi lesquels les recommandations sont sélectionnées.  \n",
    "- Différentes stratégies peuvent être utilisées :  \n",
    "  - **Tous les items disponibles** : Peut biaiser l'évaluation si le dataset est très grand.  \n",
    "  - **Items déjà vus par l’utilisateur** : Peut donner un avantage aux modèles basés sur l’historique.  \n",
    "  - **Items populaires ou filtrés** : Peut favoriser les recommandations triviales.  \n",
    "- Comparer les résultats selon différentes méthodes de sélection permet de mieux comprendre les forces et faiblesses des algorithmes.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_recommender(df):\n",
    "    metrics = df.columns[1:]  # Exclure la colonne \"recommender\"\n",
    "    best_models = []\n",
    "\n",
    "    for metric in metrics:\n",
    "        if metric in [\"RMSE (validation)\", \"MAE (validation)\", \"computation time\"]:  \n",
    "            # Pour ces métriques, on cherche la valeur minimale\n",
    "            best_row = df.loc[df[metric].idxmin()]\n",
    "        else:  \n",
    "            # Pour les autres métriques, on cherche la valeur maximale\n",
    "            best_row = df.loc[df[metric].idxmax()]\n",
    "        \n",
    "        best_models.append({\"Metric\": metric, \"Best Recommender\": best_row[\"recommender\"], \"Best Value\": best_row[metric]})\n",
    "\n",
    "    return pd.DataFrame(best_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester plusieurs valeurs de k pour KNN\n",
    "k_values = list(range(2, 50))\n",
    "\n",
    "scoring_fns = [RMSE, MAE, precision_at_k, recall_at_k, user_space_coverage, item_space_coverage, ranking_based_on_ratings]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Best Recommender</th>\n",
       "      <th>Best Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE (validation)</td>\n",
       "      <td>knn16</td>\n",
       "      <td>1.133547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training score</td>\n",
       "      <td>knn2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computation time</td>\n",
       "      <td>knn6</td>\n",
       "      <td>0.557267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAE (validation)</td>\n",
       "      <td>knn16</td>\n",
       "      <td>0.815690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>precision_at_k (validation)</td>\n",
       "      <td>knn11</td>\n",
       "      <td>0.065333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recall_at_k (validation)</td>\n",
       "      <td>knn6</td>\n",
       "      <td>0.067333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_space_coverage (validation)</td>\n",
       "      <td>knn2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>item_space_coverage (validation)</td>\n",
       "      <td>knn2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ranking_based_on_ratings (validation)</td>\n",
       "      <td>knn7</td>\n",
       "      <td>0.017346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Metric Best Recommender  Best Value\n",
       "0                      RMSE (validation)            knn16    1.133547\n",
       "1                         training score             knn2    0.000000\n",
       "2                       computation time             knn6    0.557267\n",
       "3                       MAE (validation)            knn16    0.815690\n",
       "4            precision_at_k (validation)            knn11    0.065333\n",
       "5               recall_at_k (validation)             knn6    0.067333\n",
       "6       user_space_coverage (validation)             knn2    1.000000\n",
       "7       item_space_coverage (validation)             knn2    1.000000\n",
       "8  ranking_based_on_ratings (validation)             knn7    0.017346"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommenders = [\n",
    "    {\"fn\": lambda M_train, k=k: knn.complete(M_train, k=k), \"label\": f\"knn{k}\"} \n",
    "    for k in k_values\n",
    "]\n",
    "\n",
    "df_final = None \n",
    "for scoring_fn in scoring_fns:\n",
    "    df_temp = quantitative_comparison(scoring_fn, M, recommenders, prop=0.8, nrep=3)\n",
    "    df_temp = df_temp.rename(columns={'validation score': f'{scoring_fn.__name__} (validation)'})\n",
    "    \n",
    "    if df_final is None:\n",
    "        df_final = df_temp\n",
    "    else:\n",
    "        df_final = df_final.merge(df_temp[['recommender', f'{scoring_fn.__name__} (validation)']], on='recommender')\n",
    "\n",
    "\n",
    "best_models = best_recommender(df_final)\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sauvegarde des résultats\n",
    "best_models.to_csv(\"Metrique_KNN_K.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Best Recommender</th>\n",
       "      <th>Best Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE (validation)</td>\n",
       "      <td>knn_item27</td>\n",
       "      <td>1.071630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training score</td>\n",
       "      <td>knn_item2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computation time</td>\n",
       "      <td>knn_item41</td>\n",
       "      <td>0.358192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAE (validation)</td>\n",
       "      <td>knn_item17</td>\n",
       "      <td>0.851445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>precision_at_k (validation)</td>\n",
       "      <td>knn_item2</td>\n",
       "      <td>0.042667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recall_at_k (validation)</td>\n",
       "      <td>knn_item2</td>\n",
       "      <td>0.046667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_space_coverage (validation)</td>\n",
       "      <td>knn_item2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>item_space_coverage (validation)</td>\n",
       "      <td>knn_item2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ranking_based_on_ratings (validation)</td>\n",
       "      <td>knn_item2</td>\n",
       "      <td>0.253023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Metric Best Recommender  Best Value\n",
       "0                      RMSE (validation)       knn_item27    1.071630\n",
       "1                         training score        knn_item2    0.000000\n",
       "2                       computation time       knn_item41    0.358192\n",
       "3                       MAE (validation)       knn_item17    0.851445\n",
       "4            precision_at_k (validation)        knn_item2    0.042667\n",
       "5               recall_at_k (validation)        knn_item2    0.046667\n",
       "6       user_space_coverage (validation)        knn_item2    1.000000\n",
       "7       item_space_coverage (validation)        knn_item2    1.000000\n",
       "8  ranking_based_on_ratings (validation)        knn_item2    0.253023"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tester plusieurs valeurs de k pour KNN\n",
    "recommenders = [\n",
    "    {\"fn\": lambda M_train, k=k: knn_item_based.complete_item_based(M_train, k=k), \"label\": f\"knn_item{k}\"} \n",
    "    for k in k_values\n",
    "]\n",
    "df_final = None \n",
    "for scoring_fn in scoring_fns:\n",
    "    df_temp = quantitative_comparison(scoring_fn, M, recommenders, prop=0.8, nrep=3)\n",
    "    df_temp = df_temp.rename(columns={'validation score': f'{scoring_fn.__name__} (validation)'})\n",
    "    \n",
    "    if df_final is None:\n",
    "        df_final = df_temp\n",
    "    else:\n",
    "        df_final = df_final.merge(df_temp[['recommender', f'{scoring_fn.__name__} (validation)']], on='recommender')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_models = best_recommender(df_final)\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des résultats\n",
    "best_models.to_csv(\"Metrique_KNN_K_Item.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Best Recommender</th>\n",
       "      <th>Best Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE (validation)</td>\n",
       "      <td>svd2</td>\n",
       "      <td>3.095579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training score</td>\n",
       "      <td>svd2</td>\n",
       "      <td>2.415383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computation time</td>\n",
       "      <td>svd3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAE (validation)</td>\n",
       "      <td>svd2</td>\n",
       "      <td>2.849935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>precision_at_k (validation)</td>\n",
       "      <td>svd2</td>\n",
       "      <td>0.082667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recall_at_k (validation)</td>\n",
       "      <td>svd2</td>\n",
       "      <td>0.077333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_space_coverage (validation)</td>\n",
       "      <td>svd2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>item_space_coverage (validation)</td>\n",
       "      <td>svd2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ranking_based_on_ratings (validation)</td>\n",
       "      <td>svd5</td>\n",
       "      <td>0.085546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Metric Best Recommender  Best Value\n",
       "0                      RMSE (validation)             svd2    3.095579\n",
       "1                         training score             svd2    2.415383\n",
       "2                       computation time             svd3    0.000000\n",
       "3                       MAE (validation)             svd2    2.849935\n",
       "4            precision_at_k (validation)             svd2    0.082667\n",
       "5               recall_at_k (validation)             svd2    0.077333\n",
       "6       user_space_coverage (validation)             svd2    1.000000\n",
       "7       item_space_coverage (validation)             svd2    1.000000\n",
       "8  ranking_based_on_ratings (validation)             svd5    0.085546"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tester plusieurs valeurs de k pour KNN\n",
    "recommenders = [\n",
    "    {\"fn\": lambda M_train, k=k: svd.complete(M_train, k=k), \"label\": f\"svd{k}\"} \n",
    "    for k in k_values\n",
    "]\n",
    "df_final = None \n",
    "for scoring_fn in scoring_fns:\n",
    "    df_temp = quantitative_comparison(scoring_fn, M, recommenders, prop=0.8, nrep=3)\n",
    "    df_temp = df_temp.rename(columns={'validation score': f'{scoring_fn.__name__} (validation)'})\n",
    "    \n",
    "    if df_final is None:\n",
    "        df_final = df_temp\n",
    "    else:\n",
    "        df_final = df_final.merge(df_temp[['recommender', f'{scoring_fn.__name__} (validation)']], on='recommender')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_models = best_recommender(df_final)\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des résultats\n",
    "best_models.to_csv(\"Metrique_SVD_K.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Best Recommender</th>\n",
       "      <th>Best Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE (validation)</td>\n",
       "      <td>als_2</td>\n",
       "      <td>1.361370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training score</td>\n",
       "      <td>als_2</td>\n",
       "      <td>0.578261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computation time</td>\n",
       "      <td>als_2</td>\n",
       "      <td>0.019460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAE (validation)</td>\n",
       "      <td>als_2</td>\n",
       "      <td>1.033093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>precision_at_k (validation)</td>\n",
       "      <td>als_48</td>\n",
       "      <td>0.086667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recall_at_k (validation)</td>\n",
       "      <td>als_36</td>\n",
       "      <td>0.088667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_space_coverage (validation)</td>\n",
       "      <td>als_2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>item_space_coverage (validation)</td>\n",
       "      <td>als_2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ranking_based_on_ratings (validation)</td>\n",
       "      <td>als_40</td>\n",
       "      <td>0.074912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Metric Best Recommender  Best Value\n",
       "0                      RMSE (validation)            als_2    1.361370\n",
       "1                         training score            als_2    0.578261\n",
       "2                       computation time            als_2    0.019460\n",
       "3                       MAE (validation)            als_2    1.033093\n",
       "4            precision_at_k (validation)           als_48    0.086667\n",
       "5               recall_at_k (validation)           als_36    0.088667\n",
       "6       user_space_coverage (validation)            als_2    1.000000\n",
       "7       item_space_coverage (validation)            als_2    1.000000\n",
       "8  ranking_based_on_ratings (validation)           als_40    0.074912"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommenders = [\n",
    "    {\"fn\": lambda M_train, k=k: als.complete(M_train, k=k), \"label\": f\"als_{k}\"} \n",
    "    for k in k_values\n",
    "]\n",
    "df_final = None \n",
    "for scoring_fn in scoring_fns:\n",
    "    df_temp = quantitative_comparison(scoring_fn, M, recommenders, prop=0.8, nrep=3)\n",
    "    df_temp = df_temp.rename(columns={'validation score': f'{scoring_fn.__name__} (validation)'})\n",
    "    \n",
    "    if df_final is None:\n",
    "        df_final = df_temp\n",
    "    else:\n",
    "        df_final = df_final.merge(df_temp[['recommender', f'{scoring_fn.__name__} (validation)']], on='recommender')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_models = best_recommender(df_final)\n",
    "best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des résultats\n",
    "best_models.to_csv(\"Metrique_ALS_K.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Paramétrage de méthode basée sur SVD\n",
    "\n",
    "Charger les bibliothèques et les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 400), 31553)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = load_data(tiny=False)\n",
    "M.shape, np.sum(~np.isnan(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "On fait varier $k$. Observe-t-on un phénomène de sur-apprentissage ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "recommenders = [\n",
    "   {\"fn\": lambda M_train: knn.complete(M_train, k=10), \"label\": \"knn10\"},\n",
    "    {\"fn\": lambda M_train: svd.complete(M_train, k=10), \"label\": \"svd10\"},\n",
    "    {\"fn\": lambda M_train: svd.complete(M_train, k=20), \"label\": \"svd20\"},\n",
    "    {\"fn\": lambda M_train: svd.complete(M_train, k=50), \"label\": \"svd50\"},\n",
    "    {\"fn\": lambda M_train: svd.complete(M_train, k=100), \"label\": \"svd100\"},\n",
    "    {\"fn\": lambda M_train: svd.complete(M_train, k=200), \"label\": \"svd200\"},\n",
    "    {\"fn\": lambda M_train: svd.complete(M_train, k=400), \"label\": \"svd400\"},\n",
    "    ]\n",
    "res_fill_with_zeros = quantitative_comparison(RMSE, M, recommenders, prop=0.8, nrep=4)\n",
    "res_fill_with_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oui, on observe un phénomène de sur-apprentissage (overfitting), en particulier sur les modèles SVD avec un nombre élevé de facteurs latents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\"",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "monenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
